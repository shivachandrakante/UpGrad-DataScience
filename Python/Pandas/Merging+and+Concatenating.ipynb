{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading libraries and reading the data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "market_df = pd.read_csv(\"./global_sales_data/market_fact.csv\")\n",
    "customer_df = pd.read_csv(\"./global_sales_data/cust_dimen.csv\")\n",
    "product_df = pd.read_csv(\"./global_sales_data/prod_dimen.csv\")\n",
    "shipping_df = pd.read_csv(\"./global_sales_data/shipping_dimen.csv\")\n",
    "orders_df = pd.read_csv(\"./global_sales_data/orders_dimen.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging Dataframes\n",
    "\n",
    "There are five data files:\n",
    "1. The ```market_fact``` table contains the sales data of each order\n",
    "2. The other 4 files are called 'dimension tables/files' and contain metadata about customers, products, shipping details, order details etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customer dimension table: Each row contains metadata about customers\n",
    "customer_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Product dimension table\n",
    "product_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shipping metadata\n",
    "shipping_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Orders dimension table\n",
    "orders_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging Dataframes\n",
    "\n",
    "Say you want to select all orders and observe the ```Sales``` of the customer segment *Corporate*. Since customer segment details are present in the dataframe ```customer_df```, we will first need to merge it with ```market_df```.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the dataframes\n",
    "# Note that Cust_id is the common column/key, which is provided to the 'on' argument\n",
    "# how = 'inner' makes sure that only the customer ids present in both dfs are included in the result\n",
    "df_1 = pd.merge(market_df, customer_df, how='inner', on='Cust_id')\n",
    "df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, you can subset the orders made by customers from 'Consumer' segment\n",
    "df_1.loc[df_1['Customer_Segment'] == 'CONSUMER', :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Select all orders from product category = office supplies and from the corporate segment\n",
    "# We now need to merge the product_df\n",
    "\n",
    "df_2 = pd.merge(df_1, product_df, how='inner', on='Prod_id')\n",
    "df_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all orders from product category = FURNITURE and from the consumer segment\n",
    "df_2.loc[(df_2['Product_Category']=='FURNITURE') & (df_2['Customer_Segment']=='CONSUMER'),:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Similary, you can merge the other dimension tables - ```shipping_df``` and ```orders_df``` to create a ```master_df``` and perform indexing using any column in the master dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging shipping_df\n",
    "df_3 = pd.merge(df_2, shipping_df, how='inner', on='Ship_id')\n",
    "df_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the orders table to create a master df\n",
    "master_df = pd.merge(df_3, orders_df, how='inner', on='Ord_id')\n",
    "master_df.shape\n",
    "master_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similary, you can perform left, right and outer merges (joins) by using the argument ```how = 'left' / 'right' / 'outer'```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenating Dataframes\n",
    "\n",
    "#### Concatenating Dataframes Having the Same columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframes having the same columns\n",
    "df1 = pd.DataFrame({'Name': [<4 names from class>],\n",
    "                    'Age': [<their age>],\n",
    "                    'Gender': [<their gender in 'M', 'F' format>]}\n",
    "                  )\n",
    "\n",
    "df2 = pd.DataFrame({'Name': [<3 names from class>],\n",
    "                    'Age': [<their age>],\n",
    "                    'Gender': [<their gender in 'M', 'F' format>]}\n",
    "                  )\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To concatenate them, one on top of the other, you can use pd.concat\n",
    "# The first argument is a sequence (list) of dataframes\n",
    "# axis = 0 indicates that we want to concat along the row axis\n",
    "pd.concat([df1, df2], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A useful and intuitive alternative to concat along the rows is the append() function\n",
    "# It concatenates along the rows\n",
    "df1.append(df2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenating Dataframes Having the Same Rows\n",
    "\n",
    "You may also have dataframes having the same rows but different columns (and having no common columns). In this case, you may want to concat them side-by-side. For e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'Name': [<4 names from class>],\n",
    "                    'Age': [<their age>],\n",
    "                    'Gender': [<their gender in 'M', 'F' format>]}\n",
    "                  )\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame({'School': [<their school names>],\n",
    "                    'Marks': [<12th marks>]}\n",
    "                  )\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To join the two dataframes, use axis = 1 to indicate joining along the columns axis\n",
    "# The join is possible because the corresponding rows have the same indices\n",
    "pd.concat([df1, df2], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that you can also use the ```pd.concat()``` method to merge dataframes using common keys, though here we will not discuss that. For simplicity, we have used the ```pd.merge()``` method for database-style merging and ```pd.concat()``` for appending dataframes having no common columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performing Arithmetic Operations on two or more dataframes\n",
    "\n",
    "We can also perform simple arithmetic operations on two or more dataframes. Below are the stats for IPL 2018 and 2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teamwise stats for IPL 2018\n",
    "IPL_2019 = pd.DataFrame({'IPL Team': [<short forms of the teams>],\n",
    "                         'Matches Played': [<number of matches>],\n",
    "                         'Matches Won': [<out of matches played how many won>]}\n",
    "                       )\n",
    "\n",
    "# Set the 'IPL Team' column as the index to perform arithmetic operations on the other rows using the team as reference\n",
    "IPL.set_index('IPL Team', inplace = True)\n",
    "IPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarly, we have the stats for IPL 2017\n",
    "IPL_2018 = pd.DataFrame({'IPL Team': [<short forms of the teams>],\n",
    "                         'Matches Played': [<number of matches>],\n",
    "                         'Matches Won': [<out of matches played how many won>]}\n",
    "                       )\n",
    "IPL_2018.set_index('IPL Team', inplace = True)\n",
    "IPL_2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simply add the two DFs using the add opearator\n",
    "\n",
    "Total = IPL_2019 + IPL_2018\n",
    "Total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that there are a lot of NaN values. This is because some teams which played in IPL 2018 were not present in IPL 2019. In addition, there were also new teams present in IPL 2019. We can handle these NaN values by using `df.add()` instead of the simple add operator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The fill_value argument inside the df.add() function replaces all the NaN values in the two dataframes w.r.t. each other with zero.\n",
    "Total = IPL_2019.add(IPL_2018, fill_value = 0)\n",
    "Total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also notice how the resultant dataframe is sorted by the index, i.e. 'IPL Team' alphabetically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new column - 'Win Percentage'\n",
    "\n",
    "Total['Win Percentage'] = Total['Matches Won']/Total['Matches Played']\n",
    "Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting to determine the teams with most number of wins. If the number of wins of two teams are the same, sort by the win percentage.\n",
    "\n",
    "Total.sort_values(by = (['Matches Won', 'Win Percentage']), ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apart from add(), there are also other operator-equivalent mathematical functions that you can use on Dataframes. Below is a list of all the functions that you can use to perform operations on two or more dataframes\n",
    "-  `add()`: +\n",
    "-  `sub()`: -\n",
    "-  `mul()`: *\n",
    "-  `div()`: /\n",
    "-  `floordiv()`: //\n",
    "-  `mod()`: %\n",
    "-  `pow()`: **"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
