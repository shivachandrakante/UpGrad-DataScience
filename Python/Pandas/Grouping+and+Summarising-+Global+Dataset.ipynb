{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grouping and Summarising Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading libraries and files\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "market_df = pd.read_csv(\"../global_sales_data/market_fact.csv\")\n",
    "customer_df = pd.read_csv(\"../global_sales_data/cust_dimen.csv\")\n",
    "product_df = pd.read_csv(\"../global_sales_data/prod_dimen.csv\")\n",
    "shipping_df = pd.read_csv(\"../global_sales_data/shipping_dimen.csv\")\n",
    "orders_df = pd.read_csv(\"../global_sales_data/orders_dimen.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say you want to understand how well or poorly the business is doing in various customer segments, regions, product categories etc. Specifically, you want to identify areas of business where you are incurrring heavy losses, and want to take action accordingly.\n",
    "\n",
    "To do that, we will answer questions such as:\n",
    "* Which customer segments are the least profitable?\n",
    "* Which product categories and sub-categories are the least profitable?\n",
    "* Customers in which geographic region cause the most losses?\n",
    "* Etc.\n",
    "\n",
    "First, we will merge all the dataframes, so we have all the data in one ```df```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the dataframes one by one\n",
    "df_1 = pd.merge(market_df, customer_df, how='inner', on='Cust_id')\n",
    "df_2 = pd.merge(df_1, product_df, how='inner', on='Prod_id')\n",
    "df_3 = pd.merge(df_2, shipping_df, how='inner', on='Ship_id')\n",
    "df = pd.merge(df_3, orders_df, how='inner', on='Ord_id')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1. Grouping using ```df.groupby()```\n",
    "\n",
    "Typically, you group the data using a categorical variable, such as customer segments, product categories, etc. This creates as many subsets of the data as there are levels in the categorical variable. \n",
    "\n",
    "For example, in this case, we will group the data along ```Customer_Segment```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which customer segments are the least profitable? \n",
    "# Step 1. Grouping: First, we will group the dataframe by customer segments\n",
    "df_by_segment = master_df.groupby('Customer_Segment')\n",
    "df_by_segment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that ```df.groupby``` returns a DataFrameGroupBy object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2. Applying a Function\n",
    "\n",
    "After grouping, you apply a function to a **numeric variable**, such as ```mean(Sales)```, ```sum(Profit)```, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2. Applying a function\n",
    "# We can choose aggregate functions such as sum, mean, median, etc.\n",
    "df_by_segment['Profit'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we have indexed the ```Profit``` column in the DataFrameGroupBy object exactly as we index a normal column in a dataframe. Alternatively, you could also use ```df_by_segment.Profit```. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively\n",
    "df_by_segment.Profit.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this tells us that profits are the least in the CONSUMER segment, and highest in the CORPORATE segment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For better readability, you may want to sort the summarised series:\n",
    "df_by_segment.Profit.sum().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3. Combining the results into a Data Structure\n",
    "\n",
    "You can optionally show the results as a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting to a df\n",
    "pd.DataFrame(df_by_segment['Profit'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's go through some more examples\n",
    "# E.g.: Which product categories are the least profitable?\n",
    "\n",
    "# 1. Group by product category\n",
    "by_product_cat = master_df.groupby('Product_Category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. This time, let's compare average profits\n",
    "# Apply mean() on Profit\n",
    "by_product_cat['Profit'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FURNITURE is the least profitable, TECHNOLOGY the most. Let's see which product sub-cetgories within FURNITURE are less profitable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# E.g.: Which product categories and sub-categories are the least profitable?\n",
    "# 1. Group by category and sub-category\n",
    "by_product_cat_subcat = master_df.groupby(['Product_Category', 'Product_Sub_Category'])\n",
    "by_product_cat_subcat['Profit'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, within FURNITURE, TABLES are the least profitable, followed by BOOKCASES."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recall the df.describe() method?\n",
    "# To apply multiple functions simultaneously, you can use the describe() function on the grouped df object\n",
    "by_product_cat['Profit'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some other summary functions to apply on groups\n",
    "by_product_cat['Profit'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_product_cat['Profit'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# E.g. Customers in which geographic region are the least profitable?\n",
    "master_df.groupby('Region').Profit.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that the resulting object is a Series, thus you can perform vectorised computations on them\n",
    "\n",
    "# E.g. Calculate the Sales across each region as a percentage of total Sales\n",
    "# You can divide the entire series by a number (total sales) easily \n",
    "(master_df.groupby('Region').Sales.sum() / sum(master_df['Sales']))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The regions ONTARIO, WEST and PRARIE comprise of about 64% of the sales."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
